# Pipeline Settings

# Scoring thresholds
scoring:
  minimum_score: 35  # Lowered from 40 to capture more opportunities
  top_n_jobs: 30

# Scoring weights (must sum to 100)
weights:
  semantic_similarity: 40  # 0-40 points
  skill_match: 25          # 0-25 points
  experience_fit: 15       # 0-15 points
  company_signal: 10       # 0-10 points
  penalties: 10            # -10 to +10 points

# X-Ray Search configuration
xray:
  # ATS platforms to search
  sites:
    - greenhouse.io
    - lever.co
    - ashbyhq.com
    - workable.com
    - breezy.hr
    - recruitee.com
    - jobs.lever.co
    - boards.greenhouse.io
    - wellfound.com/jobs
    - apply.workable.com
    - smartrecruiters.com
    - jobvite.com
    - careers-page.com
    - bamboohr.com
  
  # Search keywords (combined with sites)
  keywords:
    - "AI Engineer"
    - "GenAI Engineer"
    - "LLM Engineer"
    - "Applied AI"
    - "Machine Learning Engineer intern"
    - "AI intern"
    - "Generative AI"
    - "RAG"
    - "agentic"
    - "Applied ML"
    - "AI Systems"
    - "LLM Systems"
    - "Prompt Engineering"
  
  # Max results per query
  max_results_per_query: 30  # More results per query

# Hacker News scraper
hackernews:
  enabled: true
  # Search for the latest "Who's Hiring" thread

# Tavily Web Search configuration
tavily:
  api_key: ""  # Set via TAVILY_API_KEY environment variable
  enabled: true
  enrich_companies: true  # Enable company enrichment via web search
  max_enrichment_jobs: 80  # Increased from 30 (~160 credits/run, 1280/month < 1000 free tier)

# Email configuration
email:
  recipient: "nihalpardeshi12344@gmail.com"
  subject_prefix: "[AI Jobs]"

# LLM configuration (Groq)
llm:
  model: "llama-3.3-70b-versatile"
  temperature: 0  # Deterministic
  max_tokens: 2000

# Deduplication
dedup:
  # Store seen job IDs in this file
  cache_file: "data/seen_jobs.json"
